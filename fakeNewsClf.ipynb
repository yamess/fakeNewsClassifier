{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer import Trainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorch_lightning import Trainer, Callback,LightningModule\n",
    "import missingno as msno\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
    "import os\n",
    "import copy\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from fakenews import config\n",
    "\n",
    "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fakenews.model import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 06 22:50:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 442.92       Driver Version: 442.19       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1650   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   47C    P8     2W /  N/A |    477MiB /  4096MiB |     12%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1476    C+G   Insufficient Permissions                   N/A      |\n",
      "|    0      3816    C+G   ...hell.Experiences.TextInput.InputApp.exe N/A      |\n",
      "|    0      5364    C+G   ...11011.0_x64__8wekyb3d8bbwe\\Video.UI.exe N/A      |\n",
      "|    0      8244    C+G   ...dqpraam7r\\AcrobatNotificationClient.exe N/A      |\n",
      "|    0      9768    C+G   C:\\Windows\\explorer.exe                    N/A      |\n",
      "|    0     10680    C+G   ...5n1h2txyewy\\StartMenuExperienceHost.exe N/A      |\n",
      "|    0     11064    C+G   ...dows.Cortana_cw5n1h2txyewy\\SearchUI.exe N/A      |\n",
      "|    0     11504    C+G   ...x64__8wekyb3d8bbwe\\Microsoft.Photos.exe N/A      |\n",
      "|    0     11756    C+G   ...6.102.0_x64__kzf8qxf38zg5c\\SkypeApp.exe N/A      |\n",
      "|    0     11852    C+G   ...1.93.0_x64__8wekyb3d8bbwe\\YourPhone.exe N/A      |\n",
      "|    0     12144    C+G   ...mmersiveControlPanel\\SystemSettings.exe N/A      |\n",
      "|    0     14176    C+G   ...DIA GeForce Experience\\NVIDIA Share.exe N/A      |\n",
      "|    0     14756    C+G   ...1.0_x64__8wekyb3d8bbwe\\WinStore.App.exe N/A      |\n",
      "|    0     14924    C+G   ...0290.0_x64__8wekyb3d8bbwe\\HxOutlook.exe N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake = pd.read_csv('data/Fake.csv')\n",
    "train_true = pd.read_csv(\"data/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23481, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21417, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a new column to both dataframe as the target Y column either if it true or fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true['target'] = 1\n",
    "train_fake['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21417\n",
      "Name: target, dtype: int64\n",
      "0    23481\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_true.target.value_counts())\n",
    "print(train_fake.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine both dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_fake, train_true], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  target  \n",
       "0  December 31, 2017       0  \n",
       "1  December 31, 2017       0  \n",
       "2  December 30, 2017       0  \n",
       "3  December 29, 2017       0  \n",
       "4  December 25, 2017       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cfccf13be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check if there is any missing value\n",
    "%matplotlib inline\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we see there is no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification with Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  target  \n",
       "0  December 31, 2017       0  \n",
       "1  December 31, 2017       0  \n",
       "2  December 30, 2017       0  \n",
       "3  December 29, 2017       0  \n",
       "4  December 25, 2017       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_path, dropout, n_class):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert_path = bert_path\n",
    "        self.n_class = n_class\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bert = BertModel.from_pretrained(self.bert_path)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, self.n_class)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, out = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TxtDataset:\n",
    "    def __init__(self, text, target, tokenizer, max_len=512):\n",
    "        self.text = text\n",
    "        self.target = target\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "        target = int(self.target[item])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        out = {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"target\": torch.tensor(target, dtype=torch.float)\n",
    "        }\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine function definition (train, evaluation and predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    \"\"\"Loss function for binarie crossentropy\"\"\"\n",
    "    criterion = torch.nn.BCEWithLogitsLoss().to(config.DEVICE)\n",
    "    return criterion(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader):\n",
    "    total_loss = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model.train()\n",
    "    for idx, d in enumerate(tqdm(data_loader)):\n",
    "        ids = d[\"input_ids\"].to(config.DEVICE)\n",
    "        mask = d[\"mask\"].to(config.DEVICE)\n",
    "        token_type_ids = d[\"token_type_ids\"].to(config.DEVICE)\n",
    "        target = d[\"target\"].to(config.DEVICE)\n",
    "        #print(outputs)\n",
    "        #exit()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        probs = F.sigmoid(outputs)\n",
    "        print(outputs[1])\n",
    "        print(target.size())\n",
    "        exit()\n",
    "        \n",
    "        loss = loss_fn(outputs[1], target)\n",
    "        \n",
    "        # Debugging\n",
    "        #print(outputs)\n",
    "        #print(f\"loss {loss.item()}\")\n",
    "        #exit()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        y_pred.append(torch.sigmoid(outputs).cpu().detach().numpy() > 0.5)\n",
    "        y_true.append(target.cpu().detach().numpy())\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = accuracy_score(y_pred, y_true)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, optimizer, data_loader):\n",
    "    total_loss = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, d in enumerate(tqdm(data_loader)):\n",
    "            ids = d[\"input_ids\"].to(config.DEVICE)\n",
    "            mask = d[\"mask\"].to(config.DEVICE)\n",
    "            token_type_ids = d[\"token_type_ids\"].to(config.DEVICE)\n",
    "            target = d[\"target\"].to(config.DEVICE)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=ids,\n",
    "                attention_mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            loss = loss_fn(outputs,target)\n",
    "            total_loss += loss.item()\n",
    "            y_pred.append(torch.sigmoid(outputs).cpu().detach().numpy() > 0.5)\n",
    "            y_true.append(target.cpu().detach().numpy())\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        accuracy = accuracy_score(y_pred, y_true)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train steps wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.text.values\n",
    "y = data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"label\"] = train_df[\"label\"].apply(lambda x: list(map(int, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.BERT_TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = TxtDataset(\n",
    "    text=X_train,\n",
    "    target=y_train,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config.MAX_LEN\n",
    ")\n",
    "\n",
    "trainDataLoader = DataLoader(\n",
    "    dataset=trainDataset,\n",
    "    sampler=RandomSampler(trainDataset),\n",
    "    batch_size=config.TRAIN_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = TxtDataset(\n",
    "    text=X_test,\n",
    "    target=y_test,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=config.MAX_LEN\n",
    ")\n",
    "\n",
    "testDataLoader = DataLoader(\n",
    "    dataset=testDataset,\n",
    "    sampler=SequentialSampler(testDataset),\n",
    "    batch_size=config.VALID_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier(\n",
    "    bert_path=config.BERT_MODEL_PATH,\n",
    "    dropout=config.DROPOUT,\n",
    "    n_class=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_acc = 0.0\n",
    "best_epoch = 1\n",
    "output_model_file = os.path.join(config.OUTPUT_DIR, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(config.OUTPUT_DIR, CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(config.MODEL_CHECKPOINT):\n",
    "    model = BertForSequenceClassification.from_pretrained(config.OUTPUT_DIR)\n",
    "    model.to(config.DEVICE)\n",
    "    optimizer = AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    # tokenizer = BertTokenizer.from_pretrained(config.OUTPUT_DIR)\n",
    "    print(\"Loading model from last checkpoint...\")\n",
    "    state = torch.load(config.MODEL_CHECKPOINT)\n",
    "    best_valid_acc = state['best_valid_acc']\n",
    "    best_epoch = state['epoch']\n",
    "    print(f\"Best Validations Accuracy so far: {best_valid_acc:.3f} at Epoch {best_epoch}\\n\")\n",
    "else:\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "    model.to(config.DEVICE)\n",
    "    optimizer = AdamW(model.parameters(), lr=config.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config.EPOCHS):\n",
    "    real_epoch = best_epoch + epoch\n",
    "    train_loss, train_acc = train(model, optimizer, trainDataLoader)\n",
    "    test_loss, test_acc = evaluate(model, optimizer, testDataset)\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_state_dict = copy.deepcopy(model.state_dict())\n",
    "        print(\n",
    "            f\"Epoch {real_epoch: <{5}} | Train loss {train_loss:8.3f}| Train acc {train_acc:8.3f} | Valid loss {test_loss:8.3f} | Valid acc {test_acc:8.3f} | + \"\n",
    "        )\n",
    "\n",
    "        # SAVING MODEL\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)   # Saving the model\n",
    "        model_to_save.config.to_json_file(output_config_file)   # Saving model configuration\n",
    "        tokenizer.save_pretrained(config.OUTPUT_DIR)\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': real_epoch,\n",
    "            'best_valid_acc': best_test_acc,\n",
    "            'best_state_dict': best_state_dict\n",
    "        }\n",
    "        model.config.to_json_file(config.OUTPUT_DIR)\n",
    "        torch.save(checkpoint, config.MODEL_CHECKPOINT)\n",
    "    else:\n",
    "        print(\n",
    "            f'Epoch {real_epoch: <{5}} | Train loss {train_loss:8.3f}| Train acc {train_acc:8.3f} | Valid loss {test_loss:8.3f} | Valid acc {test_acc:8.3f} |'\n",
    "        )\n",
    "print(f\"The best Model Accuracy: {best_test_acc}\")\n",
    "print(\"The best Model has been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for making prediction with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tokenizer from the pretrained vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(config.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(config.OUTPUT_MODEL_FILE)\n",
    "model = BertClassifier(config.BERT_MODEL_PATH,config.DROPOUT,n_class=1)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make the prediction now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-76dec43c8528>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m21591\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m21591\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "title = data.title[21591]\n",
    "text = data.text[21591]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = preprocess(title, text, tokenizer)\n",
    "preds = predict(inputs=inputs, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': 0.46889621019363403,\n",
       " 'predictionValue': 1,\n",
       " 'predictionText': 'True News',\n",
       " 'predictionProbability': 0.6151224374771118}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the trained model to onnx runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "from transformers import BertTokenizerFast\n",
    "from fakenews.engine import preprocess, predict\n",
    "from fakenews.model import BertClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"./output/\")\n",
    "model = BertClassifier(bert_path=\"bert-base-uncased\", dropout=0.3, n_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(\"model.bin\")\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_title = data.title[24555]\n",
    "dummy_text = data.text[24555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = preprocess(title=dummy_title, text=dummy_text, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = (dummy_input[\"input_ids\"], dummy_input[\"attention_mask\"], dummy_input[\"token_type_ids\"])\n",
    "input_name = [\"input_ids\", \"attention_mask\", \"token_type_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compile to export the final onnx model\n",
    "torch.onnx.export(model, input_values, \"onnx_model.onnx\", input_names=input_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload the onnx model and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession, ExecutionMode, SessionOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the InferenceSession\n",
    "options = SessionOptions()\n",
    "options.intra_op_num_threads = 4\n",
    "options.execution_mode = ExecutionMode.ORT_PARALLEL\n",
    "session = InferenceSession(\"onnx_model.onnx\", options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.16913885]], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = session.run(\n",
    "    None, \n",
    "    {\n",
    "        \"input_ids\":dummy_input[\"input_ids\"].detach().cpu().numpy(),\n",
    "        \"attention_mask\":dummy_input[\"attention_mask\"].detach().cpu().numpy(),\n",
    "        \"token_type_ids\":dummy_input[\"token_type_ids\"].detach().cpu().numpy()\n",
    "    }\n",
    ")\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1691])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_conv = torch.tensor(logits).flatten()\n",
    "logits_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1691388487815857"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_conv.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4578157663345337"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(logits_conv).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_predict_f(inputs, model, session):\n",
    "    \"\"\"\n",
    "    1: Means Real news\n",
    "    0: Means Fake News\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        logits = session.run(\n",
    "            None, \n",
    "            {\n",
    "                \"input_ids\":inputs[\"input_ids\"].detach().cpu().numpy(),\n",
    "                \"attention_mask\":inputs[\"attention_mask\"].detach().cpu().numpy(),\n",
    "                \"token_type_ids\":inputs[\"token_type_ids\"].detach().cpu().numpy()\n",
    "            }\n",
    "        )\n",
    "        logits = torch.tensor().flatten()\n",
    "        \n",
    "        prob = torch.sigmoid(logits).item()\n",
    "        \n",
    "        y_pred = int(prob> 0.5)\n",
    "        logits = logits.item()\n",
    "        \n",
    "        y_pred_text = \"Real News\" if y_pred==0 else \"True News\"\n",
    "\n",
    "        predictions = {\n",
    "            \"logits\": logits,\n",
    "            \"predictionValue\": y_pred,\n",
    "            \"predictionText\": y_pred_text,\n",
    "            \"predictionProbability\": prob\n",
    "        }\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession, ExecutionMode, SessionOptions\n",
    "from fakenews.engine import onnx_predict, preprocess\n",
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the InferenceSession\n",
    "options = SessionOptions()\n",
    "options.intra_op_num_threads = 4\n",
    "options.execution_mode = ExecutionMode.ORT_PARALLEL\n",
    "session = InferenceSession(\"onnx_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_title = data.title[33300]\n",
    "input_text = data.text[33300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hillary Clinton also wants Britain to stay in the EU'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LONDON/WASHINGTON (Reuters) - U.S. Democratic presidential front-runner Hillary Clinton wants Britain to stay in the European Union, her campaign said on Saturday, following an intervention from U.S. President Barack Obama who urged Britons to vote to remain. “Hillary Clinton believes that transatlantic cooperation is essential, and that cooperation is strongest when Europe is united. She has always valued a strong United Kingdom in a strong EU. And she values a strong British voice in the EU,” Clinton senior policy adviser Jake Sullivan said in a statement provided to Reuters.  Clinton, who spent four years as U.S. secretary of state during Obama’s first term, has made her foreign policy credentials a central piece of her campaign for president in the November 2016 race for the White House.  Clinton’s position on the EU was first reported by Britain’s Observer newspaper.  Obama, who will leave Britain on Sunday, sparked a row during his three-day trip by bluntly telling Britain it should remain in the European Union to preserve its remaining global clout. He angered critics of the EU on Friday by warning that Britain would be at “the back of the queue” for a trade deal if it left the club - one of the strongest U.S. interventions in the affairs of a western European democracy since the Cold War. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = preprocess(title=input_title, text=input_text, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': 1.3884211778640747,\n",
       " 'predictionValue': 1,\n",
       " 'predictionText': 'Real News',\n",
       " 'predictionProbability': 0.8003401160240173}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_predict(inputs=input_data, session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"long\"] = len(data.title + data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44898"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data[\"long\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tika test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika\n",
    "from tika import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tika.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tika' has no attribute 'parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4ee92ed6cb9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtika\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tika' has no attribute 'parser'"
     ]
    }
   ],
   "source": [
    "doc = parser.from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
